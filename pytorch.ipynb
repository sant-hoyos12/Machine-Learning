{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a71604894134c42b5baca527b82337e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50f116e8c49e4298971efc41ac254904",
              "IPY_MODEL_3b0c8ac5d14f4a8ca0ea12d7cfce2531",
              "IPY_MODEL_d01542333d3e4de4a0e33581a3ef5dd4"
            ],
            "layout": "IPY_MODEL_1956821049fe4da9b0999f4b8ef9c0fb"
          }
        },
        "50f116e8c49e4298971efc41ac254904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a938a9885a254346862feb30b17a9c96",
            "placeholder": "​",
            "style": "IPY_MODEL_1d922383e0574c0c934b78c65043bc00",
            "value": "100%"
          }
        },
        "3b0c8ac5d14f4a8ca0ea12d7cfce2531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b28e2bd7c0646aeaa29312f3363d36f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_097f4c2963764b6a999734b0741f171d",
            "value": 1
          }
        },
        "d01542333d3e4de4a0e33581a3ef5dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c166dcd83d2e4d99b360448663d2ad12",
            "placeholder": "​",
            "style": "IPY_MODEL_1a32bc86749d4378b788b3252c288d68",
            "value": " 1/1 [00:19&lt;00:00, 19.33s/it]"
          }
        },
        "1956821049fe4da9b0999f4b8ef9c0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a938a9885a254346862feb30b17a9c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d922383e0574c0c934b78c65043bc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b28e2bd7c0646aeaa29312f3363d36f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097f4c2963764b6a999734b0741f171d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c166dcd83d2e4d99b360448663d2ad12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a32bc86749d4378b788b3252c288d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio de introducción a Pytorch\n",
        "Haremos un recorrido por los aspectos fundamentales de pytroch desde el manejo de tensores hasta el entrenamiento y evaluación de una red neuronal.\n",
        "Para completarlo llevamos como guía [ESTE](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb#scrollTo=u-L7YQmcHvX8) cuaderno.y otros recursos dados a lo largo del cuaderno.\n"
      ],
      "metadata": {
        "id": "vNsa-hmja1h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero importamos algunas librerías básicas"
      ],
      "metadata": {
        "id": "POmirEwBbj1P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YlhqXdgsF7fC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9e6136-556d-45c9-c5ab-b064dfc8740b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-ef889392170e>:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n"
          ]
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transform"
      ],
      "metadata": {
        "id": "UtUr7QYZHon3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero recordemos algunas funconalidades de los tensores."
      ],
      "metadata": {
        "id": "IdbqZ1kazh4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un tensor aleatorio con entradas entre 0 y 1, de tamaño 3x3\n",
        "primer_tensor = torch.rand(3, 3)\n",
        "\n",
        "# Crear un tensor de tamaño 3x3 con valores en una distribución normal estandar\n",
        "segundo_tensor = torch.randn(3, 3)\n",
        "\n",
        "# Calcular el tamaño de los tensores\n",
        "tensor_size = primer_tensor.size()\n",
        "\n",
        "# Imprimir los valores de los vectores y su tamaño\n",
        "\n",
        "print(\"Primer Tensor (Aleatorio 3x3):\")\n",
        "print(primer_tensor)\n",
        "print(\"Tamaño del Primer Tensor:\", tensor_size)\n",
        "\n",
        "print(\"\\nSegundo Tensor (Normal Estándar 3x3):\")\n",
        "print(segundo_tensor)\n",
        "print(\"Tamaño del Segundo Tensor:\", segundo_tensor.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYtN-PDlzhSP",
        "outputId": "3d5df758-7b6c-4a39-b602-8f3e70de867d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primer Tensor (Aleatorio 3x3):\n",
            "tensor([[0.3790, 0.8204, 0.9024],\n",
            "        [0.8088, 0.1526, 0.2901],\n",
            "        [0.9436, 0.6298, 0.7912]])\n",
            "Tamaño del Primer Tensor: torch.Size([3, 3])\n",
            "\n",
            "Segundo Tensor (Normal Estándar 3x3):\n",
            "tensor([[ 1.4567, -1.5909, -1.4519],\n",
            "        [ 1.3838,  1.4801, -0.4147],\n",
            "        [-1.1376, -1.0288,  1.0429]])\n",
            "Tamaño del Segundo Tensor: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una matriz de unos de tamaño 3 by 3\n",
        "tensor_of_ones = torch.ones(3, 3)\n",
        "\n",
        "# Crear una matrix identidad de tamaño 3 by 3\n",
        "identity_tensor = torch.eye(3)\n",
        "\n",
        "# Multiplicar las dos matrices anteriores\n",
        "matrices_multiplied = torch.matmul(tensor_of_ones, identity_tensor)\n",
        "print(matrices_multiplied)\n",
        "\n",
        "# ¿Qué ocurre si las multiplica usando * ?"
      ],
      "metadata": {
        "id": "-FGFp5HhNhkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7ba555-f512-4b18-cc27-31320e91107d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cuanto a la multiplicación con el operador *, esta realizará una multiplicación elemento a elemento (multiplicación Hadamard) en lugar de una multiplicación de matrices. En este caso, ambas matrices tienen el mismo tamaño, por lo que la multiplicación con * funcionaría correctamente y multiplicaría cada elemento correspondiente de ambas matrices. Sin embargo, para realizar una multiplicación matricial adecuada, debes utilizar la función torch.matmul como se muestra en el ejemplo anterior."
      ],
      "metadata": {
        "id": "lBMoxr3aeOfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cálculo de gradientes\n",
        "Calculemos un gradiente utilizando Pytorch. La función es la siguiente:\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://drive.google.com/uc?export=view&id=1rAmD2ZzVGm6bPj7DVYyhQ1tYZPTQFqAi\" width=\"700px\"></center>\n",
        "\n",
        "Para esto, puede ir a la sección Dynamic Computation Graph and Backpropagation, del cuaderno inicial."
      ],
      "metadata": {
        "id": "RNwlCf3PTdFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize x, y and z to values 4, -3 and 5\n",
        "x = torch.tensor(4.0, requires_grad=True)\n",
        "y = torch.tensor(-3.0, requires_grad=True)\n",
        "z = torch.tensor(5.0, requires_grad=True)\n",
        "\n",
        "# Set q to sum of x and y, set f to product of q with z\n",
        "q = x + y\n",
        "f = q * z\n",
        "\n",
        "# Compute the derivatives\n",
        "f.backward()\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exfqwUo0Oyb-",
        "outputId": "e0f2cb37-3a8e-479b-fdf8-52f85238c918"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of x is: tensor(5.)\n",
            "Gradient of y is: tensor(5.)\n",
            "Gradient of z is: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora calculemos los gradientes para la función descrita en la siguiente imagen:\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://drive.google.com/uc?export=view&id=1WaHCg-h4nz7PTGwYlM5R9EX8n_WNv3jI\" width=\"700px\"></center>"
      ],
      "metadata": {
        "id": "-ssM9jMBbS1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializar x,y,z como tensores aleatorios de tamaño (1000,1000)\n",
        "x = torch.randn(1000, 1000, requires_grad=True)\n",
        "y = torch.randn(1000, 1000, requires_grad=True)\n",
        "z = torch.randn(1000, 1000, requires_grad=True)\n",
        "\n",
        "# Multiplicar los tensores x con y\n",
        "q = x * y\n",
        "\n",
        "# Multiplicar componente a componente los tensores z con q\n",
        "f = z * q\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "\n",
        "# Calcular los gradientes\n",
        "mean_f.backward()\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ],
      "metadata": {
        "id": "xuyomr_DZsOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd05b1b-1fb4-4ef4-c391-06bf81379922"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of x is: tensor([[-3.2087e-07,  6.9688e-07,  4.8367e-07,  ...,  1.7413e-07,\n",
            "          2.5891e-07, -1.3880e-06],\n",
            "        [ 7.5873e-07, -1.6251e-06,  8.2395e-07,  ...,  1.8550e-06,\n",
            "         -6.4307e-07,  2.2686e-06],\n",
            "        [-3.6292e-07, -1.7868e-06,  6.8491e-07,  ..., -8.3328e-07,\n",
            "          4.2020e-08, -7.3244e-07],\n",
            "        ...,\n",
            "        [-5.2999e-07, -2.5889e-06, -1.5398e-06,  ...,  2.1023e-06,\n",
            "         -2.5166e-07,  1.7977e-07],\n",
            "        [ 2.3449e-07,  1.6045e-06,  3.2788e-08,  ...,  3.4410e-08,\n",
            "          4.2217e-07, -8.7365e-09],\n",
            "        [ 8.4237e-07,  1.6198e-08, -1.3614e-06,  ...,  1.5465e-07,\n",
            "         -1.2403e-07, -3.0991e-08]])\n",
            "Gradient of y is: tensor([[ 1.8797e-09,  2.0787e-07, -4.5042e-07,  ...,  1.7788e-07,\n",
            "          7.6858e-07, -9.6075e-07],\n",
            "        [-7.1322e-07,  1.1403e-06,  3.6076e-07,  ...,  1.1040e-06,\n",
            "         -7.7504e-07, -3.4933e-06],\n",
            "        [-9.0009e-08,  7.8000e-07,  1.0777e-06,  ..., -4.2923e-07,\n",
            "          3.6508e-08, -2.0577e-06],\n",
            "        ...,\n",
            "        [-1.8055e-07, -6.5375e-07,  2.0512e-08,  ...,  1.3719e-06,\n",
            "          1.1574e-07, -3.5132e-07],\n",
            "        [ 1.1605e-06,  1.5009e-06, -1.4446e-07,  ..., -2.1325e-08,\n",
            "         -1.7404e-06,  2.8156e-07],\n",
            "        [-1.7745e-06, -8.5494e-08, -2.6773e-07,  ...,  4.7320e-07,\n",
            "          9.2256e-08,  9.4044e-09]])\n",
            "Gradient of z is: tensor([[-2.1626e-08,  1.6044e-07, -5.5109e-07,  ...,  5.2405e-08,\n",
            "          1.9370e-07,  1.3479e-06],\n",
            "        [-1.6822e-07, -6.9957e-07,  1.9657e-06,  ...,  1.5387e-06,\n",
            "          1.3265e-06, -4.3963e-06],\n",
            "        [ 4.2728e-07, -1.6154e-06,  7.8048e-07,  ...,  1.3248e-06,\n",
            "          3.6950e-06,  1.4119e-06],\n",
            "        ...,\n",
            "        [ 1.6786e-06,  5.7908e-07, -5.5724e-08,  ...,  3.9280e-06,\n",
            "         -7.1205e-07, -1.4996e-07],\n",
            "        [ 4.3900e-07,  7.5984e-07, -1.5858e-07,  ..., -3.0431e-08,\n",
            "         -7.9307e-07, -7.2991e-10],\n",
            "        [-4.2756e-07, -3.1481e-08,  2.1239e-07,  ...,  9.1154e-07,\n",
            "         -1.9703e-06, -1.1073e-09]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcción de redes neuronales con Pytorch"
      ],
      "metadata": {
        "id": "8h8oiEp3eWTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos una red neuronal en Pytorch de forma *manual*. la entrada serán imágenes de tamaño (28,28). Es decir contienen pixeles de 784 pixeles.\n",
        "La red contendrá una capa de entrada, una capa oculta con 200 unidades y una capa de salida con 10 categorías."
      ],
      "metadata": {
        "id": "DEH8zLXhazmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer=torch.rand(784)\n",
        "# Inicializar los pesos de la red neuronal\n",
        "weight_1 = torch.rand(784, 200)  # Peso de la capa de entrada a la capa oculta\n",
        "weight_2 = torch.rand(200, 10)  # Peso de la capa oculta a la capa de salida\n",
        "\n",
        "# Multiplicar la capa de entrada con el peso 1\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "\n",
        "# Multiplicar la capa oculta con el peso 2\n",
        "output_layer = torch.matmul(hidden_1, weight_2)\n",
        "print(output_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXjt0ggwGWbb",
        "outputId": "8be358e8-7e0a-470f-c071-039a8de50689"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([19004.0312, 19508.8262, 18846.4883, 17985.2012, 18910.8184, 18079.0840,\n",
            "        20345.4258, 19242.9590, 18945.8887, 19821.1016])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora construimos la misma rede neuronal pero utilizando los módulos de Pytorch. (Ver sección *The model* del cuaderno)"
      ],
      "metadata": {
        "id": "54kg7I1udw5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Inicializar las dos capas lineales\n",
        "        self.fc1 = nn.Linear(784, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Usar las capas inicializadas y devolver x\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7bb9bFrzHBhT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construyamos la red neuronal en la gráfica siguiente, de forma *manual*\n",
        "\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://drive.google.com/uc?export=view&id=1UiW6bdXwe_jnAFU29-7P4Du1S4SqJa3R\" width=\"700px\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "mM-RqOEQfjb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear tensor aleatorio como capa de entrada\n",
        "input_layer= torch.rand(784)\n",
        "\n",
        "# Crear matrices de pesos\n",
        "weight_1= torch.rand(784, 200)\n",
        "weight_2= torch.rand(200, 200)\n",
        "weight_3= torch.rand(200, 10)\n",
        "\n",
        "# Calcular la primera y segunda capa oculta\n",
        "\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
        "\n",
        "# Imprimir la salida\n",
        "print(torch.matmul(hidden_2, weight_3))\n"
      ],
      "metadata": {
        "id": "y4CXMDaaHjym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2924a2-edee-4e24-ffb0-06ad864a8a9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2066741.3750, 1862685.5000, 1673508.6250, 2083226.6250, 1964582.6250,\n",
            "        1918253.7500, 1945435.2500, 2014283.5000, 2008317.2500, 2120144.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La anterior era una red neuronal con 2 capas ocultas ocultas en donde no se aplica ninguna función no-lineal. Veamos que ésta se puede construir con una sola capa oculta."
      ],
      "metadata": {
        "id": "iSbwtRcygzpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la compuesta de las matrices de pesos\n",
        "weight_composed_1 = torch.matmul(weight_1, weight_2)\n",
        "weight = torch.matmul(weight_composed_1, weight_3)\n",
        "\n",
        "# Multiplicar la capa de entrada por weight e imprimir\n",
        "print(torch.matmul(input_layer, weight))"
      ],
      "metadata": {
        "id": "HUVgFxvSgvHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f77cf2-bc47-4226-ff9e-ae2b4def5472"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2066742.2500, 1862686.1250, 1673507.6250, 2083227.5000, 1964583.8750,\n",
            "        1918253.2500, 1945434.0000, 2014284.7500, 2008317.2500, 2120143.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiendo de una red neuronal para reconocimiento de dígitos (MNIST Dataset)\n",
        "### Preparar los datos"
      ],
      "metadata": {
        "id": "hLcs6NtUlo-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para preparar los datos primero creamos un parámetro *transform* para transformarlos. Haremos dos cosas:\n",
        "- Transformar las imágenes del MNIST Dataset a tensores para poder alimentar la red neuronal. Esto lo hacemos con el método ToTensor.\n",
        "- Por otro lado, debemos normalizarlos con respecto a una media y variaza. Esto lo hacemos con el método Normalize. En este caso usaremos una media de 0.1307 y varianza de 0.3081. (Tenga en cuenta que en el MNIST Dataset los pixeles son en escala de grises, por lo cual sólo tienen un canal de código de color.)\n",
        "\n",
        "Para componer ambas transformaciones (Convertir a tensor y normalizar) usamos transforms.Compose ver [AQUÍ](https://www.programcreek.com/python/example/104832/torchvision.transforms.Compose)\n"
      ],
      "metadata": {
        "id": "jZkIa4FSl9h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Definir la media y la varianza para la normalización\n",
        "media = 0.1307\n",
        "varianza = 0.3081\n",
        "\n",
        "# Definir la transformación que convierte las imágenes en tensores y las normaliza\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convierte las imágenes en tensores\n",
        "    transforms.Normalize((media,), (varianza,))  # Normaliza los tensores con la media y la varianza especificadas\n",
        "])"
      ],
      "metadata": {
        "id": "lg4S9bKLS2vp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora definimos el conjunto de entrenamiento y testeo. Torchvision permite cargar datasets conocidos para visión como el MNIST.\n",
        "Para entender y completar los parámetros ver [AQUÍ](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html)."
      ],
      "metadata": {
        "id": "4of_hxAcrdpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar el conjunto de entrenamiento y prueba\n",
        "trainset = torchvision.datasets.MNIST(root='mnist', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='mnist', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "61nyqG7wrSec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abd10aa-ed47-4124-9e1b-090c091f3fef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 162694922.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24940435.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 50462542.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 17989167.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método DataLoader hace parte de torch.utils.data y permite cargar los datos por lotes de un tamaño definido. Para entender los parámetros ver [AQUÍ](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
        "Preparar los datos para entrenamiento y testeo de manera que se procesen 32 imágenes cada vez y se barajen cada vez."
      ],
      "metadata": {
        "id": "JOxpKc2StPB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar training loader y testing loader.\n",
        "# Usar los parámetros dataset, batch_size, shuffle y num_workers.\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "DCJcCLjytI5_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construya una clase para una red neuronal que será usada para entrenar el MNIST dataset. El dataset contiene imagenes de dimensiones (28,28,2), así que usted deducirá el tamaño de la capa de entrada. Para las calas ocultas use 200 unidades y para la capa de salida 10 unidades (una por cada categoría (Dígitos del 0 al 9)).\n",
        "Como función de activación use Relu de manera funcional (nn.Functional ya está importado como F).\n"
      ],
      "metadata": {
        "id": "z2ZNcnMLvjQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class Net\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "    \t# Define all the parameters of the net\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "    \t# Do the forward pass\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-v_2od5dVx33"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Entrenamiento del modelo\n",
        "\n",
        "Por favor analice cuidadosamente el siguiente código, hasta que quede claro los pasos de entrenamiento y evaluación del modelo."
      ],
      "metadata": {
        "id": "hW1FzRFVvGFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, revisemos si estamos trabajando en GPU. De lo contrario debemos cambiar el tipo de entorno de ejecución en el menú de Colab."
      ],
      "metadata": {
        "id": "P4Hd2AAqwSRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "3lSdEYQTvFFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa11d359-4be7-40c4-9691-bf93da3a9e94"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le daremos nombre a nuestro dispositivo GPU, al cual debemos transferir nuesto modelo y los datos a utilizar."
      ],
      "metadata": {
        "id": "uhlAJDQNcJRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "TIy4UMIGX72j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bfb483-c137-4115-c542-9c215c8f6592"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos nuestro modelo"
      ],
      "metadata": {
        "id": "PrDZ6975w0SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "7yVvkS2lv2eU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8debbd-8582-48aa-f5bf-0a43f7e145ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
            "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empujamos nuestro modelo al dispositivo GPU"
      ],
      "metadata": {
        "id": "T42H97fqw7O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Push model to device. Has to be only done once\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "jOvAocBcv6DD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205b8b56-9db0-4aee-cb86-30265cbece9f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el ptimizador y la función de costo"
      ],
      "metadata": {
        "id": "M0kY1SvaxFep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) # descenso de gradiente\n",
        "loss_module = nn.CrossEntropyLoss()  #función de costo"
      ],
      "metadata": {
        "id": "1GVA5xRAv98M"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo, siguiendo los 5 pasos vistos en clase"
      ],
      "metadata": {
        "id": "WGIHuKHYxJIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, testloader, loss_module, num_epochs=1):\n",
        "    # Set model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for data_inputs, data_labels in testloader:\n",
        "            data_inputs = data_inputs.view(-1, 28 * 28)\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "\n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels)\n",
        "\n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero.\n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad()\n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "Z7e83caQwBdJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, optimizer, trainloader, loss_module)"
      ],
      "metadata": {
        "id": "OxY1U-kkwFIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0a71604894134c42b5baca527b82337e",
            "50f116e8c49e4298971efc41ac254904",
            "3b0c8ac5d14f4a8ca0ea12d7cfce2531",
            "d01542333d3e4de4a0e33581a3ef5dd4",
            "1956821049fe4da9b0999f4b8ef9c0fb",
            "a938a9885a254346862feb30b17a9c96",
            "1d922383e0574c0c934b78c65043bc00",
            "5b28e2bd7c0646aeaa29312f3363d36f",
            "097f4c2963764b6a999734b0741f171d",
            "c166dcd83d2e4d99b360448663d2ad12",
            "1a32bc86749d4378b788b3252c288d68"
          ]
        },
        "outputId": "c550a57b-b6f7-444b-b6d5-2b5eb2830653"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a71604894134c42b5baca527b82337e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación evaluaremos el desempeño del modelo"
      ],
      "metadata": {
        "id": "86WV34CqcfkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total, correct =0,0\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    # Put each image into a vector\n",
        "    inputs = inputs.view(-1, 784)\n",
        "\n",
        "    # Do the forward pass and get the predictions\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    _, outputs = torch.max(outputs.data, 1) #mayor valor entre los dígitos.\n",
        "    total += labels.size(0)\n",
        "    correct += (outputs == labels).sum().item()\n",
        "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD6Z_tcOcxjI",
        "outputId": "c3db6841-cbff-4864-a631-8579a8f216d0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing set accuracy of the network is: 86 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En términos de entrenamiento de redes neuronales, se adquirió conocimiento sobre el uso del descenso de gradiente estocástico (SGD) y la retropropagación para ajustar los pesos del modelo. Esto incluyó la preparación de datos, la propagación hacia adelante y hacia atrás, así como la actualización de los pesos.\n",
        "\n",
        "También se pudo explorar la disponibilidad de GPU y cómo transferir modelos y datos entre la CPU y la GPU para acelerar el procesamiento.\n",
        "\n",
        "En términos de rendimiento, el modelo entrenado alcanzó una precisión del 86% en el conjunto de prueba del conjunto de datos MNIST. Esto significa que el modelo es capaz de reconocer correctamente el 86% de los dígitos escritos a mano en el conjunto de prueba. En otras palabras, de cada 100 dígitos en el conjunto de prueba, el modelo clasifica correctamente 86 de ellos.\n",
        "\n",
        "Esta precisión del 86% es un buen resultado para un modelo inicial sin ajuste de hiperparámetros ni técnicas avanzadas de entrenamiento. Sin embargo, hay margen de mejora, y mediante la optimización de hiperparámetros, arquitectura de red, aumento de datos y otras técnicas avanzadas, es posible lograr una mayor precisión en tareas de reconocimiento de dígitos."
      ],
      "metadata": {
        "id": "AG0QDl6eu4ji"
      }
    }
  ]
}
